{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48645512",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt\n",
    "\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from datetime import datetime\n",
    "\n",
    "# ----------------------------\n",
    "# Configuration\n",
    "# ----------------------------\n",
    "\n",
    "BASE_URL = \"https://ndhrhis.doh.gov.ph\"\n",
    "HTML_DIR = \"uploaded_html\"\n",
    "OUT_DIR = \"output_csv\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# This was parsed from the NDHRHIS archive page image you sent\n",
    "# Only includes the latest December listings per year\n",
    "YEAR_CONFIG = {\n",
    "    2024: ('02', 'As of December 31, 2024', '2025-01-03'),\n",
    "    2023: ('02', 'As of December 2023', '2024-01-02'),\n",
    "    2022: ('02', 'As of December 2022', '2023-01-04'),\n",
    "    2021: ('03', 'As of December 2021', '2022-01-03'),\n",
    "    2020: ('01', 'As of December 31, 2020', '2020-07-22'),\n",
    "    2019: ('01', 'As Of December 31, 2019', '2020-01-24'),  # capital \"Of\"\n",
    "    2018: ('01', 'As of December 31, 2018', '2018-09-07'),\n",
    "    2017: ('03', 'As of December 31, 2017 - Third set of test data', '2018-06-10'),\n",
    "}\n",
    "\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0\",\n",
    "    \"Referer\": \"https://ndhrhis.doh.gov.ph/RPA0001b.php\",\n",
    "    \"Origin\": \"https://ndhrhis.doh.gov.ph\",\n",
    "    \"Content-Type\": \"application/x-www-form-urlencoded\"\n",
    "}\n",
    "\n",
    "# ----------------------------\n",
    "# Helpers\n",
    "# ----------------------------\n",
    "\n",
    "def extract_dropdown_values(soup):\n",
    "    \"\"\"\n",
    "    Extract all non-empty dropdown (value, label) pairs, including edge cases.\n",
    "    \"\"\"\n",
    "    sel = soup.find(\"select\", attrs={\"name\": \"ddparams\"})\n",
    "    if not sel:\n",
    "        return []\n",
    "    \n",
    "    options = []\n",
    "    for opt in sel.find_all(\"option\"):\n",
    "        value = opt.get(\"value\", \"\").strip()\n",
    "        label = opt.text.strip()\n",
    "        if value and label and value.lower() != 'null':\n",
    "            options.append((value, label))\n",
    "    return options\n",
    "\n",
    "def build_post_url(level, year):\n",
    "    \"\"\"\n",
    "    Build a POST URL to request region/province/municipality for a specific year.\n",
    "    \"\"\"\n",
    "    seqn, title, gdate = YEAR_CONFIG[year]\n",
    "    return (f\"{BASE_URL}/system.bcall.page.php?xcrs=RPA0001b.php&prm=\"\n",
    "            f\"level={level}^year={year}^seqn={seqn}^title={title}^gdate={gdate}^\"\n",
    "            \"allfltr=0^prvslct=A^prvlist=^sbrep=E\")\n",
    "\n",
    "def get_html_for_year(year):\n",
    "    \"\"\"\n",
    "    Load uploaded nationwide HTML file for the given year.\n",
    "    \"\"\"\n",
    "    path = os.path.join(HTML_DIR, f\"Distribution-Nationwide {year}.html\")\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "        return BeautifulSoup(f.read(), \"lxml\")\n",
    "\n",
    "def submit_and_parse(session, url, ddvalue):\n",
    "    \"\"\"\n",
    "    Simulate POST request with dropdown selection and parse resulting page.\n",
    "    \"\"\"\n",
    "    time.sleep(0.01)\n",
    "    resp = session.post(url, headers=HEADERS, data={\"ddparams\": ddvalue, \"submit\": \"Submit\"})\n",
    "    resp.raise_for_status()\n",
    "    time.sleep(0.01)\n",
    "    return BeautifulSoup(resp.text, \"lxml\")\n",
    "\n",
    "def sanitize_filename(name):\n",
    "    \"\"\"\n",
    "    Clean directory and file names to avoid filesystem issues.\n",
    "    \"\"\"\n",
    "    return re.sub(r'[^\\w\\s-]', '', name).replace(' ', '_')\n",
    "\n",
    "def extract_and_save_tables(soup, outdir, name, year, level):\n",
    "    \"\"\"\n",
    "    Parse all valid tables from the page and save as CSVs under the specified path.\n",
    "    \"\"\"\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "    tables = soup.find_all(\"table\")\n",
    "    count = 0\n",
    "    for table in tables:\n",
    "        rows = table.find_all(\"tr\")\n",
    "        data = [[cell.get_text(strip=True) for cell in row.find_all([\"td\", \"th\"])]\n",
    "                for row in rows if row.find_all([\"td\", \"th\"])]\n",
    "        if len(data) < 2:\n",
    "            continue\n",
    "        df = pd.DataFrame(data[1:], columns=data[0])\n",
    "        fname = f\"{sanitize_filename(name)}.csv\"\n",
    "        df.to_csv(os.path.join(outdir, fname), index=False)\n",
    "        print(f\"âœ… Saved CSV: {year}/{level}/{fname}\")\n",
    "        count += 1\n",
    "    if count == 0:\n",
    "        print(f\"âš ï¸ No valid tables found for {year}/{level}/{name}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Main Routine per Year\n",
    "# ----------------------------\n",
    "\n",
    "def process_year(year):\n",
    "    session = requests.Session()\n",
    "    try:\n",
    "        print(f\"\\nðŸ” Processing year: {year}\")\n",
    "        entry_soup = get_html_for_year(year)\n",
    "        region_vals = extract_dropdown_values(entry_soup)\n",
    "\n",
    "        for region_val, region_label in region_vals:\n",
    "            try:\n",
    "                url_region = build_post_url(level=2, year=year)\n",
    "                region_soup = submit_and_parse(session, url_region, region_val)\n",
    "\n",
    "                region_dir = os.path.join(OUT_DIR, str(year), sanitize_filename(region_label))\n",
    "                extract_and_save_tables(region_soup, region_dir, region_label, year, \"Region\")\n",
    "\n",
    "                province_vals = extract_dropdown_values(region_soup)\n",
    "                for province_val, province_label in province_vals:\n",
    "                    try:\n",
    "                        url_prov = build_post_url(level=3, year=year)\n",
    "                        province_soup = submit_and_parse(session, url_prov, province_val)\n",
    "\n",
    "                        province_dir = os.path.join(region_dir, sanitize_filename(province_label))\n",
    "                        extract_and_save_tables(province_soup, province_dir, province_label, year, \"Province\")\n",
    "\n",
    "                        muni_vals = extract_dropdown_values(province_soup)\n",
    "                        for muni_val, muni_label in muni_vals:\n",
    "                            try:\n",
    "                                url_muni = build_post_url(level=4, year=year)\n",
    "                                muni_soup = submit_and_parse(session, url_muni, muni_val)\n",
    "\n",
    "                                muni_dir = os.path.join(province_dir, sanitize_filename(muni_label))\n",
    "                                extract_and_save_tables(muni_soup, muni_dir, muni_label, year, \"Municipality\")\n",
    "                            except Exception as e:\n",
    "                                print(f\"âŒ Error in municipality {muni_label}: {e}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"âŒ Error in province {province_label}: {e}\")\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Error in region {region_label}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Could not initialize year {year}: {e}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Entry Point\n",
    "# ----------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        futures = [executor.submit(process_year, year) for year in sorted(YEAR_CONFIG)]\n",
    "        for future in as_completed(futures):\n",
    "            future.result()  # Raises any errors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
